{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Demo\n",
    "\n",
    "First we read the example files, which will be annotated automatically.  \n",
    "Optionally you can pass your own tokenization method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import Records, Record\n",
    "import glob\n",
    "\n",
    "records = Records()\n",
    "for i, file in enumerate(glob.glob('data/example/*.txt')):\n",
    "    with open(file, 'r', encoding='utf-8') as r_file:\n",
    "        records.append(Record(i, r_file.read()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we build our lexicon from the `lexicon.txt` file and open the annotation GUI.  \n",
    "You can close the GUI without marking anything for this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexicon: hydrochloorthiazide\n"
     ]
    }
   ],
   "source": [
    "from data_utils import build_lexicon\n",
    "from extraction import extract_all\n",
    "from gui import AnnotationGUI\n",
    "from curation import get_false_positives\n",
    "\n",
    "lexicon = build_lexicon()\n",
    "print('Lexicon:', ', '.join(e.raw for e in lexicon.values()))\n",
    "\n",
    "extract_all(records, lexicon)  # pre-annotate tokens that are contained in the lexicon\n",
    "gui = AnnotationGUI(records)\n",
    "tags = gui.annotated\n",
    "fps = get_false_positives(records, lexicon) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next the candidatefinder will find the misspelled example after we call the `extend_fuzzy` method, and open a review GUI where it will have found the final example from its context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexicon after fuzzy matching: hydrochloorthiazide, hydrocholoorthizide\n",
      "Final lexicon: hydrochloorthiazide, hydrocholoorthizide, calci chew dD\n"
     ]
    }
   ],
   "source": [
    "from context_utils import CandidateFinder\n",
    "\n",
    "cdf = CandidateFinder(records, lexicon)  \n",
    "cdf.extend_fuzzy()  # find fuzzy matches\n",
    "print('Lexicon after fuzzy matching:', ', '.join(e.raw for e in lexicon.values()))\n",
    "cdf.process_contexts()  # find lexicon match contexts\n",
    "cdf.get_candidates()  # sets cdf.candidates to a list of candidates ordered by their occurrence count\n",
    "cdf.start_review()  # opens the review GUI\n",
    "cdf.save_all()  # saves the lexicon, rejected entries, and partial match statistics\n",
    "print('Final lexicon:', ', '.join(e.raw for e in lexicon.values()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
